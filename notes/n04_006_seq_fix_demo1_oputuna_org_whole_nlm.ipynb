{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy var generator activated\n",
      "start status is 0\n",
      "limter activated!\n",
      "dummy var generator activated\n",
      "start status is 0\n",
      "limter activated!\n",
      "reloaded!\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../nlp_assist/\")\n",
    "\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "#条件もとの3テーブルを作るモジュール\n",
    "import nlp_connect as nl\n",
    "importlib.reload(nl)\n",
    "\n",
    "#各種条件をquboとして作るためのモジュール\n",
    "import nlp_limiter as lmt\n",
    "importlib.reload(lmt)\n",
    "\n",
    "#並列で探索するソルバのラッパー\n",
    "import p_solver as ps\n",
    "importlib.reload(ps)\n",
    "\n",
    "#結果チェッカ等\n",
    "import res_parser as rps\n",
    "importlib.reload(rps)\n",
    "\n",
    "import nsp_settings as ns\n",
    "importlib.reload(ns)\n",
    "\n",
    "print(\"reloaded!\")\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230416_165205_05'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_now = datetime.datetime.now()\n",
    "dt_now.strftime('%Y%m%d_%H%M%S_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"../demos/dmk0.3_20220111_18.xlsx\"\n",
    "f2 = \"../demos/dmk0.3_20220111_18add.xlsx\"\n",
    "# x = nl.xlsx2condtion(f)\n",
    "# x.make3CDT()\n",
    "\n",
    "# # q_genはqubo generator\n",
    "# qg = lmt.q_gen(x2c=x)\n",
    "\n",
    "# nst = ns.nsp_settings()\n",
    "# inclist = nst.check_list\n",
    "# inclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1by1',\n",
       " 'cnight',\n",
       " 'cwork',\n",
       " 'dab',\n",
       " 'eqg2',\n",
       " 'eqg3',\n",
       " 'fseq',\n",
       " 'lcnn',\n",
       " 'lcnt',\n",
       " 'lfbd',\n",
       " 'lnd',\n",
       " 'mps',\n",
       " 'nnv',\n",
       " 'nseq',\n",
       " 'rqh',\n",
       " 'rqn',\n",
       " 'sc',\n",
       " 'tn',\n",
       " 'tt'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns1 = ns.nsp_settings.param_dict.copy()\n",
    "set(ns1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt_dict = dict()\n",
    "# opt_dict[0] = set(ns1.keys())\n",
    "opt_dict[0] = ('1by1','cnight',\n",
    "     'cwork',\n",
    "     'dab',\n",
    "    #  'eqg2',\n",
    "    #  'eqg3',\n",
    "     'fseq',\n",
    "     'lcnn',\n",
    "     'lcnt',\n",
    "     'lfbd',\n",
    "     'lnd',\n",
    "     'mps',\n",
    "     'nnv',\n",
    "     'nseq',\n",
    "     'rqh',\n",
    "     'rqn',\n",
    "     'sc',\n",
    "     'tn',\n",
    "     'tt')\n",
    "print(len(opt_dict[0]))\n",
    "# opt_dict[1] = ()\n",
    "# opt_dict[2] = ()\n",
    "# opt_dict[3] = ( 'eqg3', 'eqg2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1 = ns.nsp_settings.param_dict.copy()\n",
    "# d1\n",
    "# from multiprocessing import Manager\n",
    "# from multiprocessing import Pool\n",
    "# from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1by1',\n",
       " 'cnight',\n",
       " 'cwork',\n",
       " 'dab',\n",
       " 'fseq',\n",
       " 'lcnn',\n",
       " 'lcnt',\n",
       " 'lfbd',\n",
       " 'lnd',\n",
       " 'mps',\n",
       " 'nnv',\n",
       " 'nseq',\n",
       " 'rqh',\n",
       " 'rqn',\n",
       " 'sc',\n",
       " 'tn',\n",
       " 'tt')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1by1', 'cnight', 'cwork', 'dab', 'fseq', 'lcnn', 'lcnt', 'lfbd', 'lnd', 'mps', 'nnv', 'nseq', 'rqh', 'rqn', 'sc', 'tn', 'tt']\n",
      "xlsx file is\n",
      "../demos/dmk0.3_20220111_18.xlsx\n",
      "make condition tables.\n",
      "holidaymode: asHoliday\n",
      "year:  2020\n",
      "month:  10\n",
      "holidaymode:asHoliday\n",
      "days that is holiday and not sunday will be Holiday.\n",
      "Q generator activated!\n",
      "x2c need to pre make 3DT\n",
      "nsp_expression activated!\n",
      "Q dict is resetted!\n",
      "one can do one task per day...\n",
      "limit continuous work by dt1 and member capacity\n",
      "limit continious night work by dt3...\n",
      "forbiden sequence is forbiden..\n",
      "must pair must nor...\n",
      "limitting as req numbers\n",
      "limitting as req work times\n",
      "limit total tasks...\n",
      "limit tatal nights...\n",
      "last month info: duty class to forbiden seq...\n",
      "last month info: duty class to need seq...\n",
      "last month info: cont work...\n",
      "last month info: cont night work...\n",
      "shift count quantified...\n",
      "limit member pair shift...\n",
      "Veteran in each group should be preserverd.\n",
      "Night time novis should not be two in group.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 579726/579726 [00:00<00:00, 4604409.24it/s]\n"
     ]
    }
   ],
   "source": [
    "v_l = []\n",
    "v_l = v_l + list(opt_dict[0])\n",
    "print(v_l)\n",
    "\n",
    "inc = v_l\n",
    "d1 = ns.nsp_settings.param_dict.copy()\n",
    "for t in inc:\n",
    "    d1[t] = 1\n",
    "    \n",
    "x = nl.xlsx2condtion(f)\n",
    "x.make3CDT(year=2020, month=10)\n",
    "\n",
    "# q_genはqubo generator\n",
    "qg = lmt.q_gen(x2c=x)\n",
    "#qg2  = copy.deepcopy(qg)\n",
    "qg.setParam(param_dict=d1)\n",
    "# for i in inc:\n",
    "#     print(i)\n",
    "#     qg.makeAllLimitation(do_normalize=False, hideProgressBar=True, include=[i])\n",
    "#     qdf = qg.ne.getQ_asDF()\n",
    "#     print(qdf.head())\n",
    "\n",
    "qg.makeAllLimitation(do_normalize=False, hideProgressBar=True, include=inc)\n",
    "qdf = qg.ne.getQ_asDF()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215445"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(1, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-16 16:52:15,903]\u001b[0m Using an existing study with name 'nsp-study_dummy4create' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 ['1by1', 'cnight', 'cwork', 'dab', 'fseq', 'lcnn', 'lcnt', 'lfbd', 'lnd', 'mps', 'nnv', 'nseq', 'rqh', 'rqn', 'sc', 'tn', 'tt']\n",
      "[(<function objective_i at 0x000001ACD8829EE0>, 0), (<function objective_i at 0x000001ACD8829EE0>, 1), (<function objective_i at 0x000001ACD8829EE0>, 2)]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1):\n",
    "    # print(opt_dict[i])\n",
    "    v_l = []\n",
    "    for j in range(i +1):\n",
    "        v_l = v_l + list(opt_dict[j])\n",
    "    print(i, j, v_l)\n",
    "    \n",
    "    inc = v_l\n",
    "    \n",
    "    def objective_i(trial):        \n",
    "        d1 = ns.nsp_settings.param_dict.copy()\n",
    "        \n",
    "        for t in inc:\n",
    "            d1[t] = trial.suggest_int(t, 1, 256)\n",
    "            # d1[t] = trial.suggest_float(t, 1, 256)\n",
    "    \n",
    "        \n",
    "        #sweeps_log = (trial.suggest_float('sweeps_lg', 1, 10))\n",
    "        #sweeps = int(2 ** sweeps_log)\n",
    "        swmul = (trial.suggest_int('sweeps', 10, 1000))\n",
    "        #pppw = 10 **i\n",
    "        \n",
    "        # dummyseed = (trial.suggest_int('dummyseed', 1, 100000))\n",
    "        dummyseed = random.randint(1, 1000000)\n",
    "        #sw = int(sweeps * 1000)\n",
    "#         sw = 1000000\n",
    "        sw_base = 1e+4\n",
    "        sw = int(sw_base *swmul)\n",
    "        # sw = int(sweeps * 1000 * pppw)\n",
    "\n",
    "        x = nl.xlsx2condtion(f)\n",
    "        x.make3CDT(year=2020, month=10)\n",
    "\n",
    "        # q_genはqubo generator\n",
    "        qg = lmt.q_gen(x2c=x)\n",
    "        #qg2  = copy.deepcopy(qg)\n",
    "        qg.setParam(param_dict=d1)\n",
    "        qg.makeAllLimitation(do_normalize=True, hideProgressBar=True, include=inc)\n",
    "\n",
    "        p = ps.psol(q=qg.ne.getQ(),\n",
    "                 num_reads=1,\n",
    "                 sweeps=sw,\n",
    "                   seed=dummyseed\n",
    "                   )\n",
    "        mins = p.p_solve_getMin(threads=5, times=5)\n",
    "        \n",
    "        rp = rps.res_parser(x=x)\n",
    "        rp.prepRes(res=mins.sample, hideProgressBar=True)\n",
    "        rc = rps.res_checker(x=x, echo_bool=True)\n",
    "        rc.checkAllLimitation(res_parser=rp, include=inc)\n",
    "        colp_num = len(rc.log_df)\n",
    "        score = colp_num\n",
    "#         score = (colp_num + 0.0000001) * sweeps_log\n",
    "\n",
    "        if score <= 2:\n",
    "            res_dict = dict()\n",
    "            res_dict[\"mins_sample\"] = mins.sample\n",
    "            tm = rps.table_maker(x=x, res=mins.sample)\n",
    "            res_dict[\"dummyseed\"] = dummyseed\n",
    "            res_dict[\"log_df\"] = rc.log_df\n",
    "            res_dict[\"timetable\"]= tm.datetable.copy()\n",
    "            res_dict[\"shifttable\"] = tm.shifttable.copy()\n",
    "            dt_now = datetime.datetime.now()\n",
    "            ts = dt_now.strftime('%Y%m%d_%H%M%S_%f')\n",
    "            f_pkl = \"./res_dict_\"+\"error\"+str(score) +\"_\"+ts+\".pkl\"\n",
    "            # f_pkl\n",
    "            with open(f_pkl, \"wb\") as fx:\n",
    "                pickle.dump(res_dict, fx)\n",
    "\n",
    "        # score = len(rc.log_df)\n",
    "        print(\"colappse:\" +str(colp_num))\n",
    "        print('score:' + str(score))\n",
    "        gc.collect()\n",
    "\n",
    "        return score\n",
    "    \n",
    "    study_name = 'nsp-study_dummy4create'    \n",
    "    storage_file = 'sqlite:///./optuna_study_itr_whole_fix_lchs.db'\n",
    "    optuna.create_study(study_name=study_name,\n",
    "                                    storage=storage_file,\n",
    "                                    load_if_exists=True,\n",
    "                                    sampler=optuna.samplers.TPESampler(seed=114514))\n",
    "    \n",
    "#     n_trails = 1\n",
    "    n_trails = 1e+5\n",
    "#     n_trais = 1000*(i*i +1)\n",
    "    \n",
    "    def s_opt(objective, iter_num, n_trials=n_trails,  gc_after_trial=True):\n",
    "        print(\"ntraials:\" + str(n_trials))\n",
    "        # study_name = 'nsp-study_i_' + str(i)\n",
    "        study_name = 'nsp-study_deg'\n",
    "        #storage_file = 'sqlite:///./optuna_study_itr_' + str(i)+\".db\"\n",
    "        #print(study_name, storage_file)\n",
    "        study = optuna.create_study(study_name=study_name,\n",
    "                                    storage=storage_file,\n",
    "                                    load_if_exists=True,\n",
    "                                    sampler=optuna.samplers.TPESampler(seed=114514 +iter_num))\n",
    "        study.optimize(objective, n_trials=n_trials,  gc_after_trial=gc_after_trial)\n",
    "    \n",
    "\n",
    "    threads = 3\n",
    "    obj_l = [(copy.deepcopy(objective_i), t) for t in range(threads)]\n",
    "    print(obj_l)\n",
    "    r = Parallel(n_jobs=threads)( [delayed(s_opt)(objective=t[0], iter_num= t[1]) for t in obj_l] )\n",
    "    print(\"done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
